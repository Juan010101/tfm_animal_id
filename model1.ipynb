{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cac62e4-cc32-4c84-8a1d-fd68506731d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildlife_datasets import datasets, splits\n",
    "import torchvision.transforms as T\n",
    "import wildlife_tools.data.__init__ as tools\n",
    "import timm\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from active_semi_clustering.semi_supervised.pairwise_constraints import PCKMeans, COPKMeans, MKMeans, MPCKMeans, MPCKMeans, RCAKMeans\n",
    "from active_semi_clustering.semi_supervised.labeled_data import KMeans\n",
    "from active_semi_clustering.active.pairwise_constraints import ExampleOracle, ExploreConsolidate, MinMax\n",
    "from sklearn import metrics\n",
    "from active_semi_clustering.active.pairwise_constraints import ExampleOracle, ExploreConsolidate, MinMax\n",
    "import numpy as np\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b55ec5e4-3062-4aa6-b430-47e0a4e34e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/Behrouz-Babaki/COP-Kmeans/blob/master/copkmeans/cop_kmeans.py\n",
    "def preprocess_constraints(ml, cl, n):\n",
    "    \"Create a graph of constraints for both must- and cannot-links\"\n",
    "\n",
    "    # Represent the graphs using adjacency-lists\n",
    "    ml_graph, cl_graph = {}, {}\n",
    "    for i in range(n):\n",
    "        ml_graph[i] = set()\n",
    "        cl_graph[i] = set()\n",
    "\n",
    "    def add_both(d, i, j):\n",
    "        d[i].add(j)\n",
    "        d[j].add(i)\n",
    "\n",
    "    for (i, j) in ml:\n",
    "        ml_graph[i].add(j)\n",
    "        ml_graph[j].add(i)\n",
    "\n",
    "    for (i, j) in cl:\n",
    "        cl_graph[i].add(j)\n",
    "        cl_graph[j].add(i)\n",
    "\n",
    "    def dfs(i, graph, visited, component):\n",
    "        visited[i] = True\n",
    "        for j in graph[i]:\n",
    "            if not visited[j]:\n",
    "                dfs(j, graph, visited, component)\n",
    "        component.append(i)\n",
    "\n",
    "    # Run DFS from each node to get all the graph's components\n",
    "    # and add an edge for each pair of nodes in the component (create a complete graph)\n",
    "    # See http://www.techiedelight.com/transitive-closure-graph/ for more details\n",
    "    visited = [False] * n\n",
    "    neighborhoods = []\n",
    "    for i in range(n):\n",
    "        if not visited[i] and ml_graph[i]:\n",
    "            component = []\n",
    "            dfs(i, ml_graph, visited, component)\n",
    "            for x1 in component:\n",
    "                for x2 in component:\n",
    "                    if x1 != x2:\n",
    "                        ml_graph[x1].add(x2)\n",
    "            neighborhoods.append(component)\n",
    "\n",
    "    for (i, j) in cl:\n",
    "        for x in ml_graph[i]:\n",
    "            add_both(cl_graph, x, j)\n",
    "\n",
    "        for y in ml_graph[j]:\n",
    "            add_both(cl_graph, i, y)\n",
    "\n",
    "        for x in ml_graph[i]:\n",
    "            for y in ml_graph[j]:\n",
    "                add_both(cl_graph, x, y)\n",
    "\n",
    "    for i in ml_graph:\n",
    "        for j in ml_graph[i]:\n",
    "            if j != i and j in cl_graph[i]:\n",
    "                raise InconsistentConstraintsException('Inconsistent constraints between {} and {}'.format(i, j))\n",
    "\n",
    "    return ml_graph, cl_graph, neighborhoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb3cbb1b-0259-4a40-9581-65413e79b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCKMeans:\n",
    "    def __init__(self, n_clusters=3, max_iter=100, w=1):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.w = w\n",
    "\n",
    "    def fit(self, X, y=None, ml=[], cl=[]):\n",
    "        # Preprocess constraints\n",
    "        ml_graph, cl_graph, neighborhoods = preprocess_constraints(ml, cl, X.shape[0])\n",
    "\n",
    "        # Initialize centroids\n",
    "        cluster_centers = self._initialize_cluster_centers(X, neighborhoods)\n",
    "\n",
    "        # Repeat until convergence\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Assign clusters\n",
    "            labels = self._assign_clusters(X, cluster_centers, ml_graph, cl_graph, self.w)\n",
    "\n",
    "            # Estimate means\n",
    "            prev_cluster_centers = cluster_centers\n",
    "            cluster_centers = self._get_cluster_centers(X, labels)\n",
    "\n",
    "            # Check for convergence\n",
    "            difference = (prev_cluster_centers - cluster_centers)\n",
    "            converged = np.allclose(difference, np.zeros(cluster_centers.shape), atol=1e-6, rtol=0)\n",
    "\n",
    "            if converged: break\n",
    "\n",
    "        self.cluster_centers_, self.labels_ = cluster_centers, labels\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _initialize_cluster_centers(self, X, neighborhoods):\n",
    "        neighborhood_centers = np.array([X[neighborhood].mean(axis=0) for neighborhood in neighborhoods])\n",
    "        neighborhood_sizes = np.array([len(neighborhood) for neighborhood in neighborhoods])\n",
    "\n",
    "        if len(neighborhoods) > self.n_clusters:\n",
    "            # Select K largest neighborhoods' centroids\n",
    "            cluster_centers = neighborhood_centers[np.argsort(neighborhood_sizes)[-self.n_clusters:]]\n",
    "        else:\n",
    "            if len(neighborhoods) > 0:\n",
    "                cluster_centers = neighborhood_centers\n",
    "            else:\n",
    "                cluster_centers = np.empty((0, X.shape[1]))\n",
    "\n",
    "            # FIXME look for a point that is connected by cannot-links to every neighborhood set\n",
    "\n",
    "            if len(neighborhoods) < self.n_clusters:\n",
    "                remaining_cluster_centers = X[np.random.choice(X.shape[0], self.n_clusters - len(neighborhoods), replace=False), :]\n",
    "                cluster_centers = np.concatenate([cluster_centers, remaining_cluster_centers])\n",
    "\n",
    "        return cluster_centers\n",
    "\n",
    "    def _objective_function(self, X, x_i, centroids, c_i, labels, ml_graph, cl_graph, w):\n",
    "        distance = 1 / 2 * np.sum((X[x_i] - centroids[c_i]) ** 2)\n",
    "\n",
    "        ml_penalty = 0\n",
    "        for y_i in ml_graph[x_i]:\n",
    "            if labels[y_i] != -1 and labels[y_i] != c_i:\n",
    "                ml_penalty += w\n",
    "\n",
    "        cl_penalty = 0\n",
    "        for y_i in cl_graph[x_i]:\n",
    "            if labels[y_i] == c_i:\n",
    "                cl_penalty += w\n",
    "\n",
    "        return distance + ml_penalty + cl_penalty\n",
    "\n",
    "    def _assign_clusters(self, X, cluster_centers, ml_graph, cl_graph, w):\n",
    "        labels = np.full(X.shape[0], fill_value=-1)\n",
    "\n",
    "        index = list(range(X.shape[0]))\n",
    "        np.random.shuffle(index)\n",
    "        for x_i in index:\n",
    "            labels[x_i] = np.argmin([self._objective_function(X, x_i, cluster_centers, c_i, labels, ml_graph, cl_graph, w) for c_i in range(self.n_clusters)])\n",
    "\n",
    "        # Handle empty clusters\n",
    "        # See https://github.com/scikit-learn/scikit-learn/blob/0.19.1/sklearn/cluster/_k_means.pyx#L309\n",
    "        n_samples_in_cluster = np.bincount(labels, minlength=self.n_clusters)\n",
    "        empty_clusters = np.where(n_samples_in_cluster == 0)[0]\n",
    "\n",
    "        if len(empty_clusters) > 0:\n",
    "            # Encuentra índices de los puntos más distantes de los centros actuales\n",
    "            for empty_cluster in empty_clusters:\n",
    "                # Encuentra el punto más distante de cualquier centro\n",
    "                distances = np.linalg.norm(X - cluster_centers[empty_cluster], axis=1)\n",
    "                farthest_point_index = np.argmax(distances)\n",
    "\n",
    "                # Asigna el punto más distante al cluster vacío\n",
    "                labels[farthest_point_index] = empty_cluster\n",
    "\n",
    "                # Actualiza los centros para reflejar la nueva asignación\n",
    "                cluster_centers[empty_cluster] = X[farthest_point_index]\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def _get_cluster_centers(self, X, labels):\n",
    "        cluster_centers = []\n",
    "        for i in range(self.n_clusters):\n",
    "            # Verifica si hay puntos asignados al cluster\n",
    "            points_in_cluster = X[labels == i]\n",
    "            if len(points_in_cluster) == 0:\n",
    "                # Si el cluster está vacío, asigna un centro aleatorio\n",
    "                new_center = X[np.random.choice(X.shape[0])]\n",
    "            else:\n",
    "                # Calcula el centroide normalmente\n",
    "                new_center = points_in_cluster.mean(axis=0)\n",
    "            cluster_centers.append(new_center)\n",
    "        return np.array(cluster_centers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb959df-e7f6-4990-a21d-f059249efb6e",
   "metadata": {},
   "source": [
    "## Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d512174a-0b9d-48c8-a566-353e63ca136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET SeaTurtleID2022: DOWNLOADING STARTED.\n",
      "You are trying to download an already downloaded dataset.\n",
      "        This message may have happened to due interrupted download or extract.\n",
      "        To force the download use the `force=True` keyword such as\n",
      "        get_data(..., force=True) or download(..., force=True).\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset de tortugas\n",
    "dataset_path = 'data/SeaTurtleID2022'\n",
    "datasets.SeaTurtleID2022.get_data(dataset_path)\n",
    "metadata = datasets.SeaTurtleID2022(dataset_path)\n",
    "data_dftmp = metadata.df\n",
    "data_df = data_dftmp.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d4d36f-9885-482c-b558-94c18a416d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET CowDataset: DOWNLOADING STARTED.\n",
      "You are trying to download an already downloaded dataset.\n",
      "        This message may have happened to due interrupted download or extract.\n",
      "        To force the download use the `force=True` keyword such as\n",
      "        get_data(..., force=True) or download(..., force=True).\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset de tortugas\n",
    "dataset_path = 'data/CowDataset'\n",
    "datasets.CowDataset.get_data(dataset_path)\n",
    "metadata = datasets.CowDataset(dataset_path)\n",
    "data_df = metadata.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b656355-a375-411c-9449-5258b6f03f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id          873\n",
       "identity          873\n",
       "path              873\n",
       "bbox              850\n",
       "date              873\n",
       "orientation       850\n",
       "segmentation      850\n",
       "original_split    873\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0abc0-2e3a-4c26-a2e3-a33b5dbe2474",
   "metadata": {},
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130d47a1-99cf-4659-a2c8-bf770bc95244",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(size=(384, 384)),\n",
    "                              T.ToTensor(), \n",
    "                              T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "dataset = tools.WildlifeDataset(metadata=data_df, root=\"./data/SeaTurtleID2022\", transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cc078a-e8b0-4375-8749-e123b6818892",
   "metadata": {},
   "source": [
    "## Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e962c327-fa2a-4df3-84a2-e0c58a42f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 7/7 [25:35<00:00, 219.33s/it]\n"
     ]
    }
   ],
   "source": [
    "backboneDescriptor = timm.create_model(\"hf-hub:BVRA/MegaDescriptor-L-384\", pretrained=True, num_classes=0)\n",
    "extractorDescritor = DeepFeatures(backboneDescriptor)\n",
    "outputFeaturesDescritor = extractorDescritor(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "214a86e8-74c7-4088-befa-e951ad164386",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputClasses = data_df['identity'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f7d96-0fe8-4c0a-963f-e22ad80474d9",
   "metadata": {},
   "source": [
    "## Extracción del numero de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fd393ee-5381-4aa4-88bb-aa01dfa45dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfCluster = data_df['identity'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63275a0-20ea-47ac-8229-66c7e826590d",
   "metadata": {},
   "source": [
    "## Refinamiento de Caracteristicas Extraidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e3955cd-9638-4525-807c-a0fa24094c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_visualized = tsne.fit_transform(outputFeaturesDescritor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "351ec258-f4c5-40fb-a25b-eafb23fb385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_visualized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5e7e8-e274-4c7e-88b5-b526c5f6cfca",
   "metadata": {},
   "source": [
    "## Extracción de restricciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e42d5a0-ff2c-428a-8cf4-7caf2a353495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_constraints(X, y, percentage=10):\n",
    "    # Calcula todas las combinaciones de pares únicos\n",
    "    all_pairs = list(combinations(range(len(y)), 2))\n",
    "    np.random.shuffle(all_pairs)\n",
    "    \n",
    "    # Selecciona un porcentaje específico de pares\n",
    "    num_pairs = int(len(all_pairs) * percentage / 100)\n",
    "    selected_pairs = all_pairs[:num_pairs]\n",
    "    \n",
    "    must_link = []\n",
    "    cannot_link = []\n",
    "    \n",
    "    for i, j in selected_pairs:\n",
    "        if y[i] == y[j]:\n",
    "            must_link.append((i, j))\n",
    "        else:\n",
    "            cannot_link.append((i, j))\n",
    "    \n",
    "    return must_link, cannot_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cfd180e-8e1c-41df-8138-c77ad1928a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 0.8189\n"
     ]
    }
   ],
   "source": [
    "# Generar restricciones aleatorias\n",
    "must_link, cannot_link = generate_random_constraints(X_scaled, outputClasses, percentage=80)\n",
    "\n",
    "# Configurar el clustering semisupervisado\n",
    "clusterer = PCKMeans(n_clusters=numberOfCluster, max_iter=100)\n",
    "clusterer.fit(X_scaled, ml=must_link, cl=cannot_link)\n",
    "\n",
    "# Evaluar los resultados\n",
    "score = adjusted_rand_score(outputClasses, clusterer.labels_)\n",
    "print(f\"Adjusted Rand Index: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0b9a074-864a-4a62-983a-270c91285f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 0.3407\n"
     ]
    }
   ],
   "source": [
    "# Generar restricciones aleatorias\n",
    "must_link, cannot_link = generate_random_constraints(X_scaled, outputClasses, percentage=10)\n",
    "\n",
    "# Configurar el clustering semisupervisado\n",
    "clusterer = PCKMeans(n_clusters=numberOfCluster, max_iter=100)\n",
    "clusterer.fit(X_scaled, ml=must_link, cl=cannot_link)\n",
    "\n",
    "# Evaluar los resultados\n",
    "score = adjusted_rand_score(outputClasses, clusterer.labels_)\n",
    "print(f\"Adjusted Rand Index: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19bc50a1-5cfb-473e-8eda-6ab996607749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold must-link basado en densidad: 0.02359290688291398\n"
     ]
    }
   ],
   "source": [
    "def density_based_threshold_must(X, percentile=20):\n",
    "    # Entrena un modelo de vecinos más cercanos\n",
    "    nbrs = NearestNeighbors(n_neighbors=numberOfCluster).fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "    \n",
    "    # Selecciona las distancias al vecino más cercano (primer vecino, excepto el punto en sí)\n",
    "    avg_distances = distances[:, 1]  # Distancia al vecino más cercano real\n",
    "    return np.percentile(avg_distances, percentile)  # Percentil bajo para zonas densas\n",
    "\n",
    "# Aplica la función al dataset\n",
    "threshold_must = density_based_threshold_must(X_scaled)\n",
    "print(\"Threshold must-link basado en densidad:\", threshold_must)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36853c55-62fd-4983-899d-59f69b6356a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold cannot-link basado en densidad: 0.27069647591753904\n"
     ]
    }
   ],
   "source": [
    "def density_based_threshold(X, percentile=80):\n",
    "    nbrs = NearestNeighbors(n_neighbors=13).fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "    avg_distances = distances[:, -1]  # Distancia al vecino más lejano entre los 10 más cercanos\n",
    "    return np.percentile(avg_distances, percentile)\n",
    "\n",
    "threshold_cannot = density_based_threshold(X_scaled)\n",
    "print(\"Threshold cannot-link basado en densidad:\", threshold_cannot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62f18ec1-6509-41d7-9018-458b92679489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricciones must-link: [(1, 606), (9, 234), (23, 699), (41, 318), (70, 256)]\n",
      "Restricciones cannot-link: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n"
     ]
    }
   ],
   "source": [
    "def generate_constraints(X, y, threshold_must, threshold_cannot):\n",
    "    distances = euclidean_distances(X)\n",
    "    must_link = []\n",
    "    cannot_link = []\n",
    "    \n",
    "    # Recorre combinaciones de pares de puntos\n",
    "    for i, j in combinations(range(len(y)), 2):\n",
    "        if distances[i, j] <= threshold_must and y[i] == y[j]:  # misma etiqueta, distancia corta\n",
    "            must_link.append((i, j))\n",
    "        elif distances[i, j] >= threshold_cannot and y[i] != y[j]:  # diferente etiqueta, distancia larga\n",
    "            cannot_link.append((i, j))\n",
    "    \n",
    "    return must_link, cannot_link \n",
    "\n",
    "must_link, cannot_link = generate_constraints(X_scaled, outputClasses, threshold_must, threshold_cannot)\n",
    "\n",
    "print(\"Restricciones must-link:\", must_link[:5])  # Muestra las primeras 5 restricciones must-link\n",
    "print(\"Restricciones cannot-link:\", cannot_link[:5])  # Muestra las primeras 5 restricciones cannot-link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1126352-84e6-459f-b883-0640e73057bb",
   "metadata": {},
   "source": [
    "## Evaluaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2ccec-7dcd-4856-9f1a-1e9c301f530d",
   "metadata": {},
   "source": [
    "## Supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11d7ba79-d034-4e92-9749-803f73b33d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        t001       0.00      0.00      0.00         2\n",
      "        t003       0.00      0.00      0.00         0\n",
      "        t004       0.00      0.00      0.00         0\n",
      "        t014       0.00      0.00      0.00         1\n",
      "        t015       0.00      0.00      0.00         2\n",
      "        t016       0.00      0.00      0.00         1\n",
      "        t017       0.00      0.00      0.00         1\n",
      "        t018       1.00      0.50      0.67         2\n",
      "        t023       0.00      0.00      0.00         1\n",
      "        t024       0.00      0.00      0.00         1\n",
      "        t025       0.00      0.00      0.00         2\n",
      "        t026       0.00      0.00      0.00         2\n",
      "        t028       0.00      0.00      0.00         1\n",
      "        t033       0.00      0.00      0.00         1\n",
      "        t034       1.00      0.50      0.67         2\n",
      "        t035       0.00      0.00      0.00         0\n",
      "        t038       0.00      0.00      0.00         1\n",
      "        t043       0.00      0.00      0.00         1\n",
      "        t048       0.07      0.50      0.12         2\n",
      "        t052       0.00      0.00      0.00         1\n",
      "        t058       0.00      0.00      0.00         1\n",
      "        t063       0.00      0.00      0.00         0\n",
      "        t067       0.00      0.00      0.00         2\n",
      "        t068       0.00      0.00      0.00         2\n",
      "        t069       0.00      0.00      0.00         0\n",
      "        t074       0.00      0.00      0.00         1\n",
      "        t075       0.00      0.00      0.00         0\n",
      "        t076       0.00      0.00      0.00         0\n",
      "        t081       0.00      0.00      0.00         0\n",
      "        t082       0.00      0.00      0.00         1\n",
      "        t086       0.00      0.00      0.00         1\n",
      "        t090       0.00      0.00      0.00         0\n",
      "        t092       0.00      0.00      0.00         1\n",
      "        t094       0.00      0.00      0.00         2\n",
      "        t095       0.00      0.00      0.00         1\n",
      "        t096       0.00      0.00      0.00         1\n",
      "        t101       1.00      0.50      0.67         2\n",
      "        t102       0.00      0.00      0.00         1\n",
      "        t104       0.00      0.00      0.00         1\n",
      "        t110       0.00      0.00      0.00         1\n",
      "        t114       0.00      0.00      0.00         1\n",
      "        t115       0.00      0.00      0.00         0\n",
      "        t121       0.00      0.00      0.00         1\n",
      "        t136       0.00      0.00      0.00         0\n",
      "        t141       0.00      0.00      0.00         0\n",
      "        t157       0.00      0.00      0.00         1\n",
      "        t160       0.00      0.00      0.00         1\n",
      "        t162       0.00      0.00      0.00         0\n",
      "        t163       0.00      0.00      0.00         0\n",
      "        t165       0.00      0.00      0.00         0\n",
      "        t166       0.00      0.00      0.00         2\n",
      "        t172       0.00      0.00      0.00         1\n",
      "        t173       0.00      0.00      0.00         0\n",
      "        t174       0.50      0.50      0.50         2\n",
      "        t175       0.00      0.00      0.00         0\n",
      "        t189       0.20      1.00      0.33         1\n",
      "        t191       0.00      0.00      0.00         0\n",
      "        t192       0.00      0.00      0.00         1\n",
      "        t195       0.00      0.00      0.00         1\n",
      "        t199       1.00      0.33      0.50         3\n",
      "        t200       0.17      0.50      0.25         2\n",
      "        t201       0.33      0.50      0.40         4\n",
      "        t202       0.00      0.00      0.00         1\n",
      "        t204       0.20      1.00      0.33         1\n",
      "        t206       0.00      0.00      0.00         1\n",
      "        t212       0.00      0.00      0.00         3\n",
      "        t213       0.00      0.00      0.00         1\n",
      "        t216       0.00      0.00      0.00         1\n",
      "        t217       1.00      0.40      0.57         5\n",
      "        t221       0.00      0.00      0.00         3\n",
      "        t223       0.00      0.00      0.00         1\n",
      "        t224       0.00      0.00      0.00         1\n",
      "        t225       0.00      0.00      0.00         1\n",
      "        t230       0.25      0.50      0.33         2\n",
      "        t231       0.00      0.00      0.00         2\n",
      "        t232       0.00      0.00      0.00         1\n",
      "        t233       0.00      0.00      0.00         1\n",
      "        t234       0.00      0.00      0.00         1\n",
      "        t235       0.25      0.50      0.33         2\n",
      "        t236       0.00      0.00      0.00         1\n",
      "        t237       0.00      0.00      0.00         1\n",
      "        t238       0.00      0.00      0.00         2\n",
      "        t240       0.00      0.00      0.00         1\n",
      "        t241       0.00      0.00      0.00         2\n",
      "        t243       0.09      0.67      0.15         3\n",
      "        t244       0.00      0.00      0.00         2\n",
      "        t245       0.00      0.00      0.00         1\n",
      "        t246       0.00      0.00      0.00         1\n",
      "        t248       0.00      0.00      0.00         2\n",
      "        t249       0.00      0.00      0.00         1\n",
      "        t252       0.00      0.00      0.00         1\n",
      "        t254       0.00      0.00      0.00         0\n",
      "        t257       0.00      0.00      0.00         1\n",
      "        t260       0.00      0.00      0.00         2\n",
      "        t266       0.00      0.00      0.00         1\n",
      "        t267       0.00      0.00      0.00         2\n",
      "        t269       0.00      0.00      0.00         0\n",
      "        t271       0.00      0.00      0.00         1\n",
      "        t281       0.00      0.00      0.00         1\n",
      "        t283       0.00      0.00      0.00         1\n",
      "        t285       0.00      0.00      0.00         0\n",
      "        t292       0.00      0.00      0.00         0\n",
      "        t295       0.00      0.00      0.00         1\n",
      "        t296       0.00      0.00      0.00         1\n",
      "        t300       0.00      0.00      0.00         2\n",
      "        t305       0.00      0.00      0.00         2\n",
      "        t306       0.00      0.00      0.00         1\n",
      "        t310       0.00      0.00      0.00         1\n",
      "        t322       0.00      0.00      0.00         4\n",
      "        t323       0.00      0.00      0.00         5\n",
      "        t328       0.00      0.00      0.00         1\n",
      "        t333       0.00      0.00      0.00         2\n",
      "        t337       0.00      0.00      0.00         0\n",
      "        t339       0.00      0.00      0.00         1\n",
      "        t348       0.00      0.00      0.00         1\n",
      "        t350       0.00      0.00      0.00         1\n",
      "        t353       0.00      0.00      0.00         1\n",
      "        t354       0.00      0.00      0.00         2\n",
      "        t360       0.00      0.00      0.00         1\n",
      "        t362       0.00      0.00      0.00         1\n",
      "        t368       0.00      0.00      0.00         1\n",
      "        t372       0.00      0.00      0.00         1\n",
      "        t373       0.00      0.00      0.00         1\n",
      "        t374       0.00      0.00      0.00         1\n",
      "        t386       0.00      0.00      0.00         2\n",
      "        t387       0.00      0.00      0.00         1\n",
      "        t388       0.00      0.00      0.00         0\n",
      "        t390       0.00      0.00      0.00         1\n",
      "        t396       1.00      1.00      1.00         1\n",
      "        t397       1.00      0.50      0.67         2\n",
      "        t398       0.00      0.00      0.00         0\n",
      "        t415       0.00      0.00      0.00         1\n",
      "        t426       1.00      1.00      1.00         1\n",
      "        t434       0.00      0.00      0.00         1\n",
      "        t441       0.33      0.50      0.40         2\n",
      "        t442       0.00      0.00      0.00         1\n",
      "        t453       0.00      0.00      0.00         1\n",
      "        t468       0.00      0.00      0.00         1\n",
      "        t470       0.00      0.00      0.00         1\n",
      "        t473       0.00      0.00      0.00         1\n",
      "        t474       0.00      0.00      0.00         0\n",
      "        t478       0.00      0.00      0.00         2\n",
      "        t522       0.00      0.00      0.00         3\n",
      "        t527       0.00      0.00      0.00         1\n",
      "        t544       0.00      0.00      0.00         1\n",
      "        t553       0.00      0.00      0.00         0\n",
      "        t610       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.12       175\n",
      "   macro avg       0.07      0.07      0.06       175\n",
      "weighted avg       0.13      0.12      0.10       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Juanc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(outputFeaturesDescritor, outputClasses, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Escalar los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Entrenar un clasificador (por ejemplo, SVM)\n",
    "clf = SVC(kernel='linear', random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Predecir en los datos de prueba\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# 5. Evaluar el rendimiento\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ee677-ec46-4458-911c-f9294617fe2d",
   "metadata": {},
   "source": [
    "## Semi Supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7d16d2-ba06-4bc0-a5fa-64fae5bfa424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Score Promedio: 0.6473 ± 0.0362\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10  # Número de repeticiones\n",
    "rand_scores = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    clusterer = PCKMeans(n_clusters=numberOfCluster, max_iter=1000, w=0)\n",
    "    clusterer.fit(X_scaled, ml=pairwise_constraints[0], cl=pairwise_constraints[1])\n",
    "    score = adjusted_rand_score(outputClasses, clusterer.labels_)\n",
    "    rand_scores.append(score)\n",
    "\n",
    "mean_rand_score = np.mean(rand_scores)\n",
    "std_rand_score = np.std(rand_scores)\n",
    "\n",
    "print(f\"Rand Score Promedio: {mean_rand_score:.4f} ± {std_rand_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "321159bb-9bff-4e4f-95e0-1ab1f3e19d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Score Promedio: 0.0530 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1  # Número de repeticiones\n",
    "rand_scores = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    clusterer = PCKMeans(n_clusters=numberOfCluster, max_iter=100, w=1)\n",
    "    clusterer.fit(X_scaled, ml=must_link, cl=cannot_link)\n",
    "    score = adjusted_rand_score(outputClasses, clusterer.labels_)\n",
    "    rand_scores.append(score)\n",
    "\n",
    "mean_rand_score = np.mean(rand_scores)\n",
    "std_rand_score = np.std(rand_scores)\n",
    "\n",
    "print(f\"Rand Score Promedio: {mean_rand_score:.4f} ± {std_rand_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff527e3f-d3b7-4b20-9ea3-5d5c267cc112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneidad: 1.0000\n",
      "Completitud: 1.0000\n",
      "V-Measure: 1.0000\n"
     ]
    }
   ],
   "source": [
    "homogeneity = homogeneity_score(outputClasses, clusterer.labels_)\n",
    "completeness = completeness_score(outputClasses, clusterer.labels_)\n",
    "v_measure = v_measure_score(outputClasses, clusterer.labels_)\n",
    "\n",
    "print(f\"Homogeneidad: {homogeneity:.4f}\")\n",
    "print(f\"Completitud: {completeness:.4f}\")\n",
    "print(f\"V-Measure: {v_measure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123e0fe-8591-4726-b984-4fd9f12a93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10  # Número de repeticiones\n",
    "rand_scores = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    clusterer = PCKMeans(n_clusters=numberOfCluster, max_iter=100, w=1)\n",
    "    clusterer.fit(X_scaled, ml=must_link, cl=cannot_link)\n",
    "    score = adjusted_rand_score(outputClasses, clusterer.labels_)\n",
    "    rand_scores.append(score)\n",
    "\n",
    "mean_rand_score = np.mean(rand_scores)\n",
    "std_rand_score = np.std(rand_scores)\n",
    "\n",
    "print(f\"Rand Score Promedio: {mean_rand_score:.4f} ± {std_rand_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c2adb55-56a4-4774-a063-26aabcaf2cd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyClustersException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyClustersException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[0;32m      5\u001b[0m     clusterer \u001b[38;5;241m=\u001b[39m COPKMeans(n_clusters\u001b[38;5;241m=\u001b[39mnumberOfCluster, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmust_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcannot_link\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     score \u001b[38;5;241m=\u001b[39m adjusted_rand_score(outputClasses, clusterer\u001b[38;5;241m.\u001b[39mlabels_)\n\u001b[0;32m      8\u001b[0m     rand_scores\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\active_semi_supervised_clustering-0.0.1-py3.12.egg\\active_semi_clustering\\semi_supervised\\pairwise_constraints\\copkmeans.py:23\u001b[0m, in \u001b[0;36mCOPKMeans.fit\u001b[1;34m(self, X, y, ml, cl)\u001b[0m\n\u001b[0;32m     20\u001b[0m prev_cluster_centers \u001b[38;5;241m=\u001b[39m cluster_centers\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Assign clusters\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Estimate means\u001b[39;00m\n\u001b[0;32m     26\u001b[0m cluster_centers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cluster_centers(X, labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\active_semi_supervised_clustering-0.0.1-py3.12.egg\\active_semi_clustering\\semi_supervised\\pairwise_constraints\\copkmeans.py:49\u001b[0m, in \u001b[0;36mCOPKMeans._assign_clusters\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m retries_cnt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries_cnt):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_assign_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ClusteringNotFoundException:\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\active_semi_supervised_clustering-0.0.1-py3.12.egg\\active_semi_clustering\\semi_supervised\\pairwise_constraints\\copkmeans.py:80\u001b[0m, in \u001b[0;36mCOPKMeans._try_assign_clusters\u001b[1;34m(self, X, cluster_centers, dist, ml_graph, cl_graph)\u001b[0m\n\u001b[0;32m     77\u001b[0m empty_clusters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(n_samples_in_cluster \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(empty_clusters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyClustersException\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "\u001b[1;31mEmptyClustersException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_runs = 10  # Número de repeticiones\n",
    "rand_scores = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    clusterer = COPKMeans(n_clusters=numberOfCluster, max_iter=100)\n",
    "    clusterer.fit(X_scaled, outputClasses, ml=must_link, cl=cannot_link)\n",
    "    score = adjusted_rand_score(outputClasses, clusterer.labels_)\n",
    "    rand_scores.append(score)\n",
    "\n",
    "mean_rand_score = np.mean(rand_scores)\n",
    "std_rand_score = np.std(rand_scores)\n",
    "\n",
    "\n",
    "print(f\"Rand Score Promedio: {mean_rand_score:.4f} ± {std_rand_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e2815-e0a4-4fca-bcaa-08a657aba876",
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity = homogeneity_score(outputClasses, clusterer.labels_)\n",
    "completeness = completeness_score(outputClasses, clusterer.labels_)\n",
    "v_measure = v_measure_score(outputClasses, clusterer.labels_)\n",
    "\n",
    "print(f\"Homogeneidad: {homogeneity:.4f}\")\n",
    "print(f\"Completitud: {completeness:.4f}\")\n",
    "print(f\"V-Measure: {v_measure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8469d-4d9e-46aa-8faa-b2e6a6eaf440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da630bb-21a1-4760-8e05-e14a2a09d963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062d407-dd18-42b2-a4b1-8cac5e46783b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
